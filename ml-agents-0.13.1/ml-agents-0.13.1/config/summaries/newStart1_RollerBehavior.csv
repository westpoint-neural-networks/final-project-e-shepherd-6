Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length,Losses/Value Loss,Losses/Policy Loss
1000,1.4221483,0.00029998503,0.06303719,-0.29317062772101693,-0.29317062854138115,254.2941176470588,0.009058357,0.23986673
2000,1.415971,0.00029995505,-0.015312807,-0.26167228466106784,-0.2616722855144771,363.44444444444446,0.0035933617,0.24380016
3000,1.4091929,0.00029992504,-0.12738872,-0.18085265306657866,-0.18085265727543293,310.94736842105266,0.0028583799,0.2504435
4000,1.4014744,0.000299895,-0.05692022,-0.12356432780091252,-0.12356433133585856,403.57142857142856,0.0053448733,0.24379548
5000,1.3859744,0.000299865,-0.02984174,-0.2493366948639353,-0.2493367043850109,391.6666666666667,0.0030443063,0.24372536
6000,1.3775834,0.00029983502,-0.03922765,-0.1415692359352341,-0.1415692394405666,463.84615384615387,0.00016395186,0.2444521
7000,1.3710238,0.00029980502,-0.047212813,-0.2461557974322484,-0.24615579749577313,441.3076923076923,0.0014976793,0.2462995
8000,1.3573089,0.00029977504,-0.06653969,-0.2545143127042268,-0.2545143183993527,435.85714285714283,0.0011833172,0.24786684
