Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length,Losses/Value Loss,Losses/Policy Loss
1000,1.4132456,0.00029999999,-0.5220984,-0.5258449984101367,-0.5258449939418928,67.10126582278481,0.03579978,0.24681543
2000,1.3893291,0.00029999999,-0.19924995,-0.4327550592167037,-0.432755055486736,143.71428571428572,0.0104252845,0.24533065
3000,1.3782659,0.00029999999,-0.069857374,-0.07977336452653011,-0.0797733708684973,422.4,0.0027936618,0.24892151
4000,1.3692049,0.00029999999,-0.09570364,-0.36546411289600655,-0.36546411536210144,353.8125,0.0028518466,0.24676736
5000,1.3400266,0.00029999999,-0.09282296,-0.3305460956241739,-0.33054609653606204,342.2631578947368,0.005259811,0.24036494
6000,1.3194907,0.00029999999,-0.16182524,-0.378519512195554,-0.37851951232086223,292.0,0.0033297043,0.23916157
7000,1.3090054,0.00029999999,-0.071242124,-0.16656878928188235,-0.16656879628487786,384.6875,0.0039033534,0.24487755
8000,1.301009,0.00029999999,-0.05986934,-0.10641878680326045,-0.10641879210970728,362.375,0.0031927228,0.24552318
9000,1.2916436,0.00029999999,-0.0035556348,-0.25918340822681785,-0.25918341055451793,358.55555555555554,0.0050613224,0.24356507
