Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length,Losses/Value Loss,Losses/Policy Loss
1000,1.4364908,0.00029999999,-0.17854276,-0.31873618792693986,-0.31873619159250666,225.0,0.021547073,0.24819584
2000,1.4635508,0.00029999999,0.05805731,-0.12430663323520046,-0.12430663830893632,316.57894736842104,0.007614458,0.24575421
3000,1.462421,0.00029999999,0.031144073,-0.022910967061761767,-0.02291096381065927,401.25,0.0062175845,0.24690999
4000,1.4384326,0.00029999999,-0.02861558,-0.3267550229405363,-0.3267550273093851,429.4,0.0008329547,0.24504583
5000,1.4191915,0.00029999999,-0.10124473,-0.5142625265030397,-0.5142625335349496,298.94444444444446,0.0008966498,0.24305356
6000,1.3890574,0.00029999999,-0.11550161,-0.3144056074735191,-0.3144056083111637,328.94444444444446,0.0032578162,0.24555644
7000,1.3590403,0.00029999999,0.0017630373,-0.06759253088384867,-0.06759253354457542,293.95,0.004964795,0.24153501
8000,1.3264846,0.00029999999,-0.08190901,-0.2719762242798294,-0.27197623055672876,302.3333333333333,0.0019339666,0.24139069
9000,1.3308731,0.00029999999,-0.24836412,-0.5021005318433579,-0.5021005391897039,111.14285714285714,0.0055393362,0.2387402
